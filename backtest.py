# -*- coding: utf-8 -*-
"""backtest

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Opl9VAxjhJepBH2AeQ2JzuN9Dzf42Uo
"""

# Static Cont-Kukanov split across N venues (single snapshot)

# Inputs
#   order_size  – target shares to buy (e.g. 5_000)
#   venues      – list of objects, one per venue, each with:
#                 .ask  .ask_size  .fee  .rebate
#   λ_over      – cost penalty per extra share bought
#   λ_under     – cost penalty per unfilled share
#   θ_queue     – queue-risk penalty (linear in total mis-execution)
#
# Outputs
#   best_split  – list[int]  shares sent to each venue (len == N)
#   best_cost   – float      total expected cost of that split

#-------------Packages & Library------------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
from datetime import datetime, timedelta

#----------------Functions--------------------------------------
# Trading Cost
def compute_cost(split, venues, order_size, lambda_o, lambda_u, theta):
    executed = 0
    cash_spent = 0
    for i in range(0,len(venues)): # i is the information of time t in different venues
        exe = min(split[i], venues[i]['ask_size'])
        executed += exe
        cash_spent += exe * (venues[i]['ask'] + venues[i]['fee'])
        maker_rebate = max(split[i] - exe, 0) * venues[i]['rebate']     # why the rebate is calculated based on unexecuted size?
        cash_spent -= maker_rebate

    underfill = max(order_size-executed, 0)
    overfill  = max(executed-order_size, 0)
    risk_pen  = theta * (underfill + overfill)
    cost_pen  = lambda_u * underfill + lambda_o * overfill
    return cash_spent + risk_pen + cost_pen

#allocater
def allocate(order_size, venues, lambda_o, lambda_u, theta):
    step = 100
    splits = [[]]

    for v in range(len(venues)):
        new_splits = []
        for alloc in splits:
            used = sum(alloc)
            max_v = min(order_size - used, venues[v]['ask_size'])
            for q in range(0, int(max_v) + 1, step):
                new_splits.append(alloc + [q])
        splits = new_splits

    best_cost = float('inf')
    best_split = []
    for alloc in splits:
        executed = sum(alloc)
        if executed == 0:
            continue  # skip no-trade allocations

        cost = compute_cost(alloc, venues, executed, lambda_o, lambda_u, theta)
        if cost < best_cost:
            best_cost = cost
            best_split = alloc

    return best_split, best_cost

#----------------------BASELINE MODELS-------------------------------------

# Best Ask Strategy
def best_ask_everyXs(
        snapshots,
        timestamps,            # ← one timestamp per snapshot
        total_order_size,
        lambda_o,
        lambda_u,
        theta,
        min_gap              # seconds between fills
):
    """
    consecutive executions are ≥ min_gap seconds apart.
    """
    remaining_order  = total_order_size
    total_cost       = 0.0
    total_executed   = 0
    execution_log    = []

    last_exec_time   = None                 # no trade yet

    for t, (venue, ts) in enumerate(zip(snapshots, timestamps)):
        alloc = [0] * len(venue)
        if remaining_order <= 0:
            break

        # rate-limit: skip until ≥ min_gap seconds have elapsed
        if last_exec_time is not None and (ts - last_exec_time).total_seconds() < min_gap:
            continue

        # choose the venue with the best ask
        best_id   = min(range(len(venue)), key=lambda i: venue[i]['ask'])
        best_size = venue[best_id]['ask_size']
        executed  = min(remaining_order, best_size)
        if executed == 0:
            continue

        alloc[best_id] = executed

        cost = compute_cost(alloc, venue, executed,
                            lambda_o, lambda_u, theta)

        # book the fill
        total_cost      += cost
        total_executed  += executed
        remaining_order -= executed
        last_exec_time   = ts                # reset the timer

        execution_log.append({
            'snapshot' : t,
            'time'     : ts,
            'alloc'    : alloc,
            'executed' : executed,
            'remaining': remaining_order,
            'cost'     : cost
        })

    avg_fill_price = (total_cost / total_executed) if total_executed else None
    return execution_log, total_cost, avg_fill_price


# TWAP Strategy
def twap(snapshots, timestamps, total_order_size, lambda_o, lambda_u, theta, bucket_seconds=60):
    """
    Improved TWAP: Uniformly splits order over time buckets,
    allows partial fills, and carries over unfilled amounts.
    """
    if not snapshots or not timestamps:
        return [], 0.0, None

    start_time = timestamps[0]
    end_time = timestamps[-1]
    total_seconds = (end_time - start_time).total_seconds()
    num_buckets = int(total_seconds // bucket_seconds) + 1

    shares_per_bucket = total_order_size // num_buckets
    leftover = total_order_size - shares_per_bucket * num_buckets

    remaining_order = total_order_size
    total_cost = 0.0
    total_executed = 0
    execution_log = []
    bucket_tracker = [0] * num_buckets  # allow reuse of buckets

    for t, (snapshot, ts) in enumerate(zip(snapshots, timestamps)):
        if remaining_order <= 0:
            break

        bucket_idx = int((ts - start_time).total_seconds() // bucket_seconds)
        bucket_idx = min(bucket_idx, num_buckets - 1)

        # Skip if already attempted too many times (e.g., 1 try per second in a bucket)
        if bucket_tracker[bucket_idx] > 3:
            continue
        bucket_tracker[bucket_idx] += 1

        shares_to_buy = shares_per_bucket
        if bucket_idx == num_buckets - 1:
            shares_to_buy += leftover  # absorb total remainder at the end

        alloc = [0] * len(snapshot)
        executed = 0

        for i, venue in enumerate(snapshot):
            fill = min(venue['ask_size'], shares_to_buy - executed)
            alloc[i] = fill
            executed += fill
            if executed >= shares_to_buy:
                break

        if executed == 0:
            continue

        # Carry forward leftover to next round
        unfilled = shares_to_buy - executed
        leftover += unfilled

        cost = compute_cost(alloc, snapshot, executed, lambda_o, lambda_u, theta)
        total_cost += cost
        total_executed += executed
        remaining_order -= executed

        execution_log.append({
            'snapshot': t,
            'time': ts,
            'bucket': bucket_idx,
            'alloc': alloc,
            'executed': executed,
            'remaining': remaining_order,
            'cost': cost
        })

    avg_fill_price = total_cost / total_executed if total_executed > 0 else None
    return execution_log, total_cost, avg_fill_price


# def twap(snapshots, timestamps, total_order_size, lambda_o, lambda_u, theta, bucket_seconds=60):
#     start_time = timestamps[0]
#     total_seconds = (timestamps[-1] - start_time).total_seconds()
#     num_buckets = int(total_seconds // bucket_seconds) + 1

#     shares_per_bucket = total_order_size // num_buckets
#     remainder = total_order_size - shares_per_bucket * num_buckets

#     remaining_order = total_order_size
#     total_cost = 0
#     total_executed = 0
#     execution_log = []
#     used_buckets = set()

#     for t in range(len(snapshots)):
#         if remaining_order <= 0:
#             break

#         bucket_idx = int((timestamps[t] - start_time).total_seconds() // bucket_seconds)
#         if bucket_idx in used_buckets:
#             continue

#         snapshot = snapshots[t]
#         shares_to_buy = shares_per_bucket + (remainder if bucket_idx == num_buckets - 1 else 0)

#         alloc = [0] * len(snapshot)
#         executed = 0

#         for i, venue in enumerate(snapshot):
#             buy_amt = min(venue['ask_size'], shares_to_buy - executed)
#             alloc[i] = buy_amt
#             executed += buy_amt
#             if executed >= shares_to_buy:
#               break

#         if executed == 0:
#             continue

#         cost = compute_cost(alloc, snapshot, executed, lambda_o, lambda_u, theta)
#         total_cost += cost
#         total_executed += executed
#         remaining_order -= executed

#         used_buckets.add(bucket_idx)
#         execution_log.append({
#             'snapshot': t,
#             'alloc': alloc,
#             'executed': executed,
#             'remaining': remaining_order,
#             'cost': cost
#         })

#     avg_fill_price = total_cost / total_executed if total_executed > 0 else None
#     return execution_log, total_cost, avg_fill_price



def vwap(snapshots, total_order_size, lambda_o, lambda_u, theta):
    """
    Execute order using VWAP: split each execution proportionally to ask sizes.
    """
    remaining_order = total_order_size
    total_cost = 0
    total_executed = 0
    execution_log = []

    for t, snapshot in enumerate(snapshots):
        if remaining_order <= 0:
            break

        total_ask_size = sum(v['ask_size'] for v in snapshot)
        if total_ask_size == 0:
            continue

        alloc = [min(remaining_order * v['ask_size'] / total_ask_size, v['ask_size']) for v in snapshot]
        alloc = [int(s) for s in alloc]
        executed = sum(alloc)

        if executed == 0:
            continue

        cost = compute_cost(alloc, snapshot, executed, lambda_o, lambda_u, theta)
        total_cost += cost
        total_executed += executed
        remaining_order -= executed

        execution_log.append({
            'snapshot': t,
            'alloc': alloc,
            'executed': executed,
            'remaining': remaining_order,
            'cost': cost
        })

    avg_fill_price = total_cost / total_executed if total_executed > 0 else None

    return execution_log, total_cost, avg_fill_price


#---------Smart_Order_Router--------------------
def static_cont_kukanov(
    snapshots,
    timestamps,
    total_order_size,
    lambda_o,
    lambda_u,
    theta,
    min_gap
):
    """
    Greedy Cont-Kukanov allocator with time pacing.
    """
    remaining_order = total_order_size
    total_cost = 0.0
    total_executed = 0
    execution_log = []
    last_exec_time = None
    start_time = timestamps[0] + timedelta(seconds=2)

    for t, (venues, ts) in enumerate(zip(snapshots, timestamps)):
        if ts < start_time:
            continue
        if remaining_order <= 0:
            break
        if last_exec_time is not None and (ts - last_exec_time).total_seconds() < min_gap:
            continue

        # Use greedy allocator
        alloc, cost = allocate(remaining_order, venues, lambda_o, lambda_u, theta)
        #print(f"  Allocation: {alloc}, cost: {cost}")
        executed = sum(alloc)
        if executed == 0:
            continue

        remaining_order -= executed
        total_cost += cost
        total_executed += executed
        last_exec_time = ts

        execution_log.append({
            'snapshot': t,
            'time': ts,
            'alloc': alloc,
            'executed': executed,
            'remaining': remaining_order,
            'cost': cost
        })

    avg_price = total_cost / total_executed if total_executed > 0 else None
    return execution_log, total_cost, avg_price

# grid search for parameters
def grid_search_parameters(
    snapshots,
    timestamps,
    total_order_size,
    lambda_over_vals,
    lambda_under_vals,
    theta_vals
):
    best_params = None
    best_cost = float('inf')
    best_log = None

    for lo in lambda_over_vals:
        for lu in lambda_under_vals:
            for th in theta_vals:
                log, cost, _ = static_cont_kukanov(
                    snapshots,
                    timestamps,
                    total_order_size,
                    lo,
                    lu,
                    th,
                    min_gap=1
                )
                if cost < best_cost:
                    best_cost = cost
                    best_params = {
                        'lambda_over': lo,
                        'lambda_under': lu,
                        'theta_queue': th
                    }
                    best_log = log

    return best_params, best_cost, best_log



# plot
def plot_cum_costs(logs_dict, filename='results.png'):
    n = len(logs_dict)
    ncols = 2
    nrows = (n + ncols - 1) // ncols
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 4 * nrows), sharex=True)
    axes = axes.flatten()

    for ax, (label, log) in zip(axes, logs_dict.items()):
        snapshots = [entry['snapshot'] for entry in log]
        costs = [entry['cost'] for entry in log]
        cumulative = [sum(costs[:i+1]) for i in range(len(costs))]

        ax.plot(snapshots, cumulative, label=label, linewidth=2)
        ax.scatter(snapshots, cumulative, color='black', s=20)
        ax.set_title(label)
        ax.set_ylabel('Cumulative Cost')
        ax.grid(True)
        ax.legend()

    for i in range(len(logs_dict), len(axes)):
        fig.delaxes(axes[i])  # remove unused axes

    plt.xlabel('Execution Step')
    plt.tight_layout()
    plt.savefig(filename)

    plt.plot(x_axis, cum_cost, label=label, marker='o')  # explicitly mark points


# data preparation
def load_data(file_name):
    df = pd.read_csv(file_name)
    df = df[['ts_event', 'publisher_id', 'ask_px_00', 'ask_sz_00']]

    df['ts_event'] = pd.to_datetime(df['ts_event'])
    df = df.sort_values(by = ['ts_event','publisher_id'])
    df = df.drop_duplicates(subset = ['ts_event','publisher_id'],keep='first')


    snapshots = []
    timestamps = []
    for timestamp, group in df.groupby('ts_event'):
        venue = []
        for _, row in group.iterrows():
            venue.append({
                'ask': float(row['ask_px_00']),
                'ask_size':float(row['ask_sz_00']),
                'fee':0.03,
                'rebate': -0.002
            })
        snapshots.append(venue)
        timestamps.append(timestamp)

    return timestamps, snapshots


if __name__ == "__main__":
    timestamps, snapshots = load_data('l1_day.csv')
    total_order_size = 5000

    # Step 1: Parameter tuning first
    best_params, best_cost, best_log = grid_search_parameters(
        snapshots, timestamps, total_order_size,
        lambda_over_vals=[0.05, 0.1, 0.2],
        lambda_under_vals=[0.01, 0.05, 0.1],
        theta_vals=[0.005, 0.01]
    )

    lambda_o = best_params['lambda_over']
    lambda_u = best_params['lambda_under']
    theta = best_params['theta_queue']


    # Step 2: Run all strategies with tuned parameters
    logs = {}
    logs['BestAskXs'], cost_ba5s, avg_ba5s = best_ask_everyXs(
    snapshots,
    timestamps,          # ← pass the list you already built
    total_order_size,
    lambda_o,
    lambda_u,
    theta,
    min_gap=5
    )
    logs['TWAP'], cost_twap, avg_twap = twap(snapshots, timestamps, total_order_size, lambda_o, lambda_u, theta)
    logs['VWAP'], cost_vwap, avg_vwap = vwap(snapshots, total_order_size, lambda_o, lambda_u, theta)
    logs['static_cont_kukanov'], cost_2, avg_2 = static_cont_kukanov(snapshots, timestamps, total_order_size, lambda_o, lambda_u, theta, min_gap=10)


    def plot_log_cum_costs(logs, filename=None, use_timestamps=False, log_base='natural'):
        """
        Plot log of cumulative execution costs for multiple strategies.
        """
        plt.figure(figsize=(10, 6))

        for label, exec_log in logs.items():
            if not exec_log:
                continue

            cum_cost = []
            x_axis = []
            running_total = 0.0

            for i, row in enumerate(exec_log):
                running_total += row['cost']
                x_val = row['time'] if use_timestamps else i

                # Log transformation (safe for 0)
                if log_base == 'natural':
                    log_cost = np.log1p(running_total)  # ln(1 + x)
                elif log_base == 'log10':
                    log_cost = np.log10(1 + running_total)
                else:
                    raise ValueError("log_base must be 'natural' or 'log10'")

                cum_cost.append(log_cost)
                #x_axis.append(x_val)
                x_axis.append(row['time'] if use_timestamps else i)

            plt.plot(x_axis, cum_cost, label=label)

        plt.title("Log of Cumulative Execution Cost per Strategy")
        plt.xlabel("Timestamp" if use_timestamps else "Execution Step")
        plt.ylabel("log(Cumulative Cost)")
        plt.legend()
        plt.grid(True)

        if filename:
            plt.savefig(filename, dpi=300)

        plt.show()

    plot_log_cum_costs(logs, filename="result.png", use_timestamps=False, log_base='natural')

    #---------Final output according to spec------------------
    output = {
        "Tuned_Parameters": best_params,
        "SmartRouter": {
            "total_cost": best_cost,
            "avg_fill_price": best_cost / total_order_size,
            "savings_vs_bestask_bps": round(10000 * (cost_ba5s - best_cost) / cost_ba5s, 2),
            "savings_vs_twap_bps": round(10000 * (cost_twap - best_cost) / cost_twap, 2),
            "savings_vs_vwap_bps": round(10000 * (cost_vwap - best_cost) / cost_vwap, 2)
        },
        "BestAsk": {
            "total_cost": cost_ba5s,
            "avg_fill_price": avg_ba5s
        },
        "TWAP": {
            "total_cost": cost_twap,
            "avg_fill_price": avg_twap
        },
        "VWAP": {
            "total_cost": cost_vwap,
            "avg_fill_price": avg_vwap
        }
    }
    print(json.dumps(output, indent=2))
    with open("result.json", "w") as f:
        json.dump(output, f, indent=2)
        print("Saved JSON output to execution_summary.json")

